{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bd80078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "823aaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from\n",
    "# https://raw.githubusercontent.com/twitterdev/Twitter-API-v2-sample-code/master/Recent-Search/recent_search.py\n",
    "\n",
    "def auth(): return os.getenv('BEARER_TOKEN')\n",
    "\n",
    "def create_url(query, next_token=None, tweet_fields=None):\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    \n",
    "    next_token = ('next_token=' + next_token) if next_token is not None else ''\n",
    "    tweet_fields = tweet_fields if tweet_fields is not None else ''\n",
    "    \n",
    "    url = 'https://api.twitter.com/2/tweets/search/recent?query={}&{}&{}'.format(query, tweet_fields, next_token)\n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_tweets(account, next_token=None):\n",
    "    bearer_token = auth()\n",
    "    url = create_url('from:' + account, next_token, tweet_fields='tweet.fields=created_at')\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6c35f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTION_A = r'([0-9]*) appointments available at (.*?)( in (.*?), MA)? on ([0-9]{4}[-][0-9]{2}[-][0-9]{2}|[0-9]{1,2}/[0-9]{1,2}/[0-9]{4})( for (.*?))?\\. Check eligibility and sign up at (.*?)$'\n",
    "OPTION_B = r'(.*?) appointments available in (.*?)\\. Check eligibility and sign up at (.*?)$'\n",
    "\n",
    "COMP_A = re.compile(OPTION_A)\n",
    "COMP_B = re.compile(OPTION_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9451a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_upper(phrase):\n",
    "    return ' '.join(map(lambda x: x.capitalize(), phrase.split(' ')))\n",
    "\n",
    "def extract_details_a(entry):\n",
    "    match_a = COMP_A.match(entry['text'])\n",
    "    if match_a is None: return None\n",
    "    \n",
    "    (count, site, _, locality, date, _, vaccine_type, website) = match_a.groups()\n",
    "    \n",
    "    try: date = dt.strptime(date, '%Y-%m-%d')\n",
    "    except:\n",
    "        try: date = dt.strptime(date, '%m/%d/%Y')\n",
    "        except: date = None\n",
    "\n",
    "    row = pd.DataFrame([{\n",
    "        'id': entry['id'],\n",
    "        'count': int(count),\n",
    "        'site': to_upper(site),\n",
    "        'locality': to_upper(locality) if locality is not None else None,\n",
    "        'date': date,\n",
    "        'vaccine_type': to_upper(vaccine_type) if vaccine_type is not None else None,\n",
    "        'posted': dt.strptime(entry['created_at'], '%Y-%m-%dT%H:%M:%S.%fZ'),\n",
    "        'website': website.lower()\n",
    "    }])\n",
    "    return row\n",
    "\n",
    "def extract_details_b(entry):\n",
    "    match_b = COMP_B.match(entry['text'])\n",
    "    if match_b is None: return None\n",
    "    (site, localities, website) = match_b.groups()\n",
    "    date = dt.strptime(entry['created_at'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    \n",
    "    rows = pd.DataFrame([{\n",
    "        'id': entry['id'],\n",
    "        'count': None,\n",
    "        'site': '{} - {}'.format(to_upper(site), to_upper(locality.strip())),\n",
    "        'locality': to_upper(locality.strip()),\n",
    "        'date': date,\n",
    "        'vaccine_type': None,\n",
    "        'posted': date,\n",
    "        'website': website.lower()\n",
    "    } for locality in localities.split(',')])\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5aba9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(stop_id=None):\n",
    "    \n",
    "    data = []\n",
    "    ids = set()\n",
    "    next_token = None\n",
    "    isFirstRun = True\n",
    "    newest_id = None\n",
    "\n",
    "    while isFirstRun or (stop_id not in ids and next_token is not None):\n",
    "        response = get_tweets('vaccinetime', next_token)\n",
    "        if isFirstRun: newest_id = response['meta']['newest_id']\n",
    "        data += response['data']\n",
    "        ids = set(map(lambda x: x['id'], response['data']))\n",
    "        try: next_token = response['meta']['next_token']\n",
    "        except: next_token = None\n",
    "        isFirstRun = False\n",
    "            \n",
    "    if stop_id is not None:\n",
    "        stop_id_index = (\n",
    "            len(data) -\n",
    "            next(i for i, v in enumerate(reversed(data), 1) if v['id'] == stop_id)\n",
    "        )\n",
    "        data = data[:stop_id_index]\n",
    "    return (data, newest_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "65abfaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FILE = 'data/data.csv'\n",
    "METADATA_FILE = 'data/metadata.json'\n",
    "\n",
    "def fetch_new_data():\n",
    "    latest_id = None\n",
    "    try:\n",
    "        with open(METADATA_FILE) as fopen:\n",
    "            metadata = json.loads(fopen.read())\n",
    "            latest_id = metadata['latest_id']\n",
    "    except: pass\n",
    "    return get_data(latest_id)\n",
    "\n",
    "def cache_data(df, newest_id):\n",
    "    try:\n",
    "        df.to_csv(CACHE_FILE, mode='a', header=False, index=False)\n",
    "        with open(METADATA_FILE, 'w') as fopen:\n",
    "            fopen.write(json.dumps({ 'last_updated': dt.now().isoformat(), 'latest_id': newest_id }))\n",
    "    except: pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "18bb877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_frame(data):\n",
    "    rows = []\n",
    "    for entry in data:\n",
    "        try:\n",
    "            details = extract_details_a(entry)\n",
    "            if details is None: details = extract_details_b(entry)\n",
    "            if details is not None: rows.append(details)\n",
    "            else: print('[ERROR] NO MATCH FOR', '`' + entry['text'] + '`')\n",
    "        except: print('[ERROR] MATCHING FAILED FOR', '`' + entry['text'] + '`')\n",
    "    return pd.concat(rows) if len(rows) > 0 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d39ce1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data():\n",
    "    (data, newest_id) = fetch_new_data()\n",
    "    df = data_to_frame(data)\n",
    "    if df is None:\n",
    "        print('no new data')\n",
    "        return\n",
    "    else: print(len(df), 'new records')\n",
    "    cache_data(df, newest_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "24e9f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no new data\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": pull_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03eea80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
